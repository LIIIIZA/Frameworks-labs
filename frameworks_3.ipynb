{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Классификация"
      ],
      "metadata": {
        "id": "bH2SGidJVXDi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Бейзлайн из библиотеки"
      ],
      "metadata": {
        "id": "aXMwz7-qKQlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score, precision_recall_curve, auc\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, average_precision_score, classification_report\n",
        "\n",
        "df = pd.read_csv('placementdata.csv')\n",
        "\n",
        "label_encoders = {}\n",
        "binary_columns = ['ExtracurricularActivities', 'PlacementTraining', 'PlacementStatus']\n",
        "\n",
        "for col in binary_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "X = df.drop(columns=['StudentID', 'PlacementStatus'])\n",
        "y = df['PlacementStatus'].copy()\n",
        "\n",
        "X_orig_train, X_orig_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "X_v1_train = X_orig_train.copy()\n",
        "X_v1_test = X_orig_test[X_v1_train.columns]\n",
        "\n",
        "dt_v1 = DecisionTreeClassifier(random_state=42)\n",
        "dt_v1.fit(X_v1_train, y_train)\n",
        "y_pred_v1 = dt_v1.predict(X_v1_test)\n",
        "y_proba_v1 = dt_v1.predict_proba(X_v1_test)[:, 1]\n",
        "\n",
        "f1_v1 = f1_score(y_test, y_pred_v1)\n",
        "precision_v1, recall_v1, _ = precision_recall_curve(y_test, y_proba_v1)\n",
        "pr_auc_v1 = auc(recall_v1, precision_v1)\n",
        "\n",
        "print(f\"F1-мера: {f1_v1:.4f}\")\n",
        "print(f\"PR AUC: {pr_auc_v1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MSu-gjiTf1b",
        "outputId": "bebd055c-922e-4044-d09d-e4bbd11557ac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-мера: 0.6663\n",
            "PR AUC: 0.7372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Улучшенный бейзлайн"
      ],
      "metadata": {
        "id": "oBuJXwksKrqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_original = df[['SSC_Marks', 'HSC_Marks', 'CGPA', 'Projects', 'Workshops/Certifications', 'AptitudeTestScore', 'Internships', 'SoftSkillsRating']].copy()\n",
        "X_new = X_original.copy()\n",
        "\n",
        "X_new['Average_Marks'] = (X_new['SSC_Marks'] + X_new['HSC_Marks'] + X_new['CGPA']) / 3\n",
        "X_new['Total_Activities'] = X_new['Projects'] + X_new['Internships'] + X_new['Workshops/Certifications']\n",
        "X_new['CGPA_Aptitude_Score'] = X_new['CGPA'] * X_new['AptitudeTestScore']\n",
        "X_new['Projects_And_Internships'] = X_new['Projects'] + X_new['Internships']\n",
        "X_new['Normalized_CGPA'] = X_new['CGPA'] / 10.0\n",
        "X_new['High_Aptitude'] = (X_new['AptitudeTestScore'] > 70).astype(int)\n",
        "X_new['Activity_Skill_Index'] = (X_new['Projects'] + X_new['Internships'] + X_new['Workshops/Certifications']) * X_new['SoftSkillsRating']\n",
        "\n",
        "X_new_train, X_new_test, _, _ = train_test_split(X_new, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "X_v2_train = X_new_train[['Activity_Skill_Index', 'Normalized_CGPA', 'High_Aptitude']].copy()\n",
        "X_v2_test = X_new_test[X_v2_train.columns]\n",
        "dt_v2 = DecisionTreeClassifier(random_state=42)\n",
        "dt_v2.fit(X_v2_train, y_train)\n",
        "y_pred_v2 = dt_v2.predict(X_v2_test)\n",
        "y_proba_v2 = dt_v2.predict_proba(X_v2_test)[:, 1]\n",
        "\n",
        "f1_v2 = f1_score(y_test, y_pred_v2)\n",
        "precision_v2, recall_v2, _ = precision_recall_curve(y_test, y_proba_v2)\n",
        "pr_auc_v2 = auc(recall_v2, precision_v2)\n",
        "\n",
        "print(f\"F1-мера: {f1_v2:.4f}\")\n",
        "print(f\"PR AUC: {pr_auc_v2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4juR4ujUYqE",
        "outputId": "1c56bc47-679a-4f2d-de3a-6a8d7957ad9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-мера: 0.6941\n",
            "PR AUC: 0.6934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создание новых признаков улучшило метрику F1, но ухудшило PR AUC, нужна дальнейшая работа"
      ],
      "metadata": {
        "id": "T61TmXA1K-Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10, None],\n",
        "    'min_samples_split': [2, 10, 20],\n",
        "    'min_samples_leaf': [1, 5, 10],\n",
        "    'class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "grid_search_v3 = GridSearchCV(\n",
        "    DecisionTreeClassifier(random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='f1'\n",
        ")\n",
        "grid_search_v3.fit(X_v2_train, y_train)\n",
        "\n",
        "best_dt_v3 = grid_search_v3.best_estimator_\n",
        "\n",
        "y_pred_v3 = best_dt_v3.predict(X_v2_test)\n",
        "y_pred_proba_v3 = best_dt_v3.predict_proba(X_v2_test)[:, 1]\n",
        "\n",
        "f1_v3 = f1_score(y_test, y_pred_v3)\n",
        "pr_auc_v3 = auc(precision_recall_curve(y_test, y_pred_proba_v3)[1], precision_recall_curve(y_test, y_pred_proba_v3)[0])\n",
        "\n",
        "print(f\"F1-мера: {f1_v3:.4f}\")\n",
        "print(f\"PR AUC: {pr_auc_v3:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4NpYUwrRr0w",
        "outputId": "653aacf0-305f-49fe-8a84-3509b5b1ed84"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-мера: 0.7308\n",
            "PR AUC: 0.7992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подбор гиперпараметров в сочетании с новыми признаками заметно улучшили обе метрики по сравнению с бейзлайном"
      ],
      "metadata": {
        "id": "Wegumy0yLTHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Имплементация бейзлайн"
      ],
      "metadata": {
        "id": "uWSeQ6XrYKoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import f1_score, precision_recall_curve, auc, classification_report\n",
        "\n",
        "def entropy(y):\n",
        "    if len(y) == 0:\n",
        "        return 0\n",
        "    counts = Counter(y)\n",
        "    probs = [count / len(y) for count in counts.values()]\n",
        "    return -sum(p * np.log2(p) for p in probs if p > 0)\n",
        "\n",
        "def information_gain(y, y_left, y_right):\n",
        "    n = len(y)\n",
        "    n_l, n_r = len(y_left), len(y_right)\n",
        "    if n_l == 0 or n_r == 0:\n",
        "        return 0\n",
        "    h = entropy(y)\n",
        "    h_l = entropy(y_left)\n",
        "    h_r = entropy(y_right)\n",
        "    return h - (n_l / n) * h_l - (n_r / n) * h_r\n",
        "\n",
        "class DecisionNode:\n",
        "    def __init__(self, feature_idx=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature_idx = feature_idx\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=100, min_samples_split=2, min_samples_leaf=1):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.root = None\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        best_gain = -1\n",
        "        best_feature_idx = None\n",
        "        best_threshold = None\n",
        "        current_entropy = entropy(y)\n",
        "\n",
        "        if current_entropy == 0:\n",
        "            return None, None\n",
        "\n",
        "        n_features = X.shape[1]\n",
        "        for feature_idx in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature_idx])\n",
        "            for threshold in thresholds:\n",
        "                left_mask = X[:, feature_idx] <= threshold\n",
        "                right_mask = ~left_mask\n",
        "\n",
        "                y_left, y_right = y[left_mask], y[right_mask]\n",
        "\n",
        "                if len(y_left) < self.min_samples_leaf or len(y_right) < self.min_samples_leaf:\n",
        "                    continue\n",
        "\n",
        "                gain = information_gain(y, y_left, y_right)\n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_feature_idx = feature_idx\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature_idx, best_threshold\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        n_labels = len(np.unique(y))\n",
        "\n",
        "        if (depth >= self.max_depth or\n",
        "            n_labels == 1 or\n",
        "            n_samples < self.min_samples_split):\n",
        "            leaf_value = self._most_common_label(y)\n",
        "            return DecisionNode(value=leaf_value)\n",
        "\n",
        "        feature_idx, threshold = self._best_split(X, y)\n",
        "        if feature_idx is None:\n",
        "            leaf_value = self._most_common_label(y)\n",
        "            return DecisionNode(value=leaf_value)\n",
        "\n",
        "        left_mask = X[:, feature_idx] <= threshold\n",
        "        right_mask = ~left_mask\n",
        "\n",
        "        left_child = self._grow_tree(X[left_mask], y[left_mask], depth + 1)\n",
        "        right_child = self._grow_tree(X[right_mask], y[right_mask], depth + 1)\n",
        "\n",
        "        return DecisionNode(feature_idx=feature_idx, threshold=threshold, left=left_child, right=right_child)\n",
        "\n",
        "    def _most_common_label(self, y):\n",
        "        counter = Counter(y)\n",
        "        value = counter.most_common(1)[0][0]\n",
        "        return value\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self._grow_tree(X, y)\n",
        "        return self\n",
        "\n",
        "    def _predict_sample(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "\n",
        "        if x[node.feature_idx] <= node.threshold:\n",
        "            return self._predict_sample(x, node.left)\n",
        "        else:\n",
        "            return self._predict_sample(x, node.right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_sample(x, self.root) for x in X])\n",
        "\n",
        "df = pd.read_csv('placementdata.csv')\n",
        "\n",
        "df_processed = df.copy()\n",
        "\n",
        "binary_columns = ['ExtracurricularActivities', 'PlacementTraining']\n",
        "for col in binary_columns:\n",
        "    le = LabelEncoder()\n",
        "    df_processed[col] = le.fit_transform(df_processed[col])\n",
        "\n",
        "target_encoder = LabelEncoder()\n",
        "df_processed['PlacementStatus'] = target_encoder.fit_transform(df_processed['PlacementStatus'])\n",
        "\n",
        "X = df_processed.drop(columns=['StudentID', 'PlacementStatus'])\n",
        "y = df_processed['PlacementStatus'].copy()\n",
        "\n",
        "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "X_train_orig_np = X_train_orig.values\n",
        "X_test_orig_np = X_test_orig.values\n",
        "y_train_orig_np = y_train_orig.values\n",
        "y_test_orig_np = y_test_orig.values\n",
        "\n",
        "tree_simple = DecisionTree(min_samples_split=5, min_samples_leaf=2)\n",
        "tree_simple.fit(X_train_orig_np, y_train_orig_np)\n",
        "y_pred_simple = tree_simple.predict(X_test_orig_np)\n",
        "\n",
        "f1_simple = f1_score(y_test_orig_np, y_pred_simple)\n",
        "precision_simple, recall_simple, _ = precision_recall_curve(y_test_orig_np, y_pred_simple)\n",
        "pr_auc_simple = auc(recall_simple, precision_simple)\n",
        "\n",
        "print(f\"F1-мера: {f1_simple:.4f}\")\n",
        "print(f\"PR AUC: {pr_auc_simple:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Cla3iY4MUsX",
        "outputId": "3c893f8c-8889-4bfc-cc9c-f383a9ceed2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-мера: 0.6738\n",
            "PR AUC: 0.7411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Имплементированный алгоритм показал примерно такие же результаты, что и бейзлайн из библиотеки"
      ],
      "metadata": {
        "id": "qaKxqaffQsZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = X.copy()\n",
        "\n",
        "X_new['Average_Marks'] = (X_new['SSC_Marks'] + X_new['HSC_Marks'] + X_new['CGPA']) / 3\n",
        "X_new['Total_Activities'] = X_new['Projects'] + X_new['Internships'] + X_new['Workshops/Certifications']\n",
        "X_new['CGPA_Aptitude_Score'] = X_new['CGPA'] * X_new['AptitudeTestScore']\n",
        "X_new['Projects_And_Internships'] = X_new['Projects'] + X_new['Internships']\n",
        "X_new['Normalized_CGPA'] = X_new['CGPA'] / 10.0\n",
        "X_new['High_Aptitude'] = (X_new['AptitudeTestScore'] > 70).astype(int)\n",
        "X_new['Activity_Skill_Index'] = (X_new['Projects'] + X_new['Internships'] + X_new['Workshops/Certifications']) * X_new['SoftSkillsRating']\n",
        "\n",
        "X_improved_df = X_new[['Activity_Skill_Index', 'Normalized_CGPA', 'High_Aptitude']].copy()\n",
        "\n",
        "X_train_imp, X_test_imp, y_train_imp, y_test_imp = train_test_split(X_improved_df, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "X_train_imp_np = X_train_imp.values\n",
        "X_test_imp_np = X_test_imp.values\n",
        "y_train_imp_np = y_train_imp.values\n",
        "y_test_imp_np = y_test_imp.values\n",
        "\n",
        "best_f1 = -1\n",
        "best_params = {}\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_samples_split': [2, 10, 20],\n",
        "    'min_samples_leaf': [1, 5, 10]\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "for md in param_grid['max_depth']:\n",
        "    for mss in param_grid['min_samples_split']:\n",
        "        for msl in param_grid['min_samples_leaf']:\n",
        "            cv_f1_scores = []\n",
        "            for train_idx, val_idx in cv.split(X_train_imp_np, y_train_imp_np):\n",
        "                X_tr_cv, X_val_cv = X_train_imp_np[train_idx], X_train_imp_np[val_idx]\n",
        "                y_tr_cv, y_val_cv = y_train_imp_np[train_idx], y_train_imp_np[val_idx]\n",
        "\n",
        "                tree_cv = DecisionTree(max_depth=md, min_samples_split=mss, min_samples_leaf=msl)\n",
        "                tree_cv.fit(X_tr_cv, y_tr_cv)\n",
        "                y_pred_cv = tree_cv.predict(X_val_cv)\n",
        "                cv_f1_scores.append(f1_score(y_val_cv, y_pred_cv))\n",
        "\n",
        "            mean_f1 = np.mean(cv_f1_scores)\n",
        "            if mean_f1 > best_f1:\n",
        "                best_f1 = mean_f1\n",
        "                best_params = {'max_depth': md, 'min_samples_split': mss, 'min_samples_leaf': msl}\n",
        "\n",
        "tree_improved = DecisionTree(**best_params)\n",
        "tree_improved.fit(X_train_imp_np, y_train_imp_np)\n",
        "y_pred_improved = tree_improved.predict(X_test_imp_np)\n",
        "\n",
        "f1_improved = f1_score(y_test_imp_np, y_pred_improved)\n",
        "precision_improved, recall_improved, _ = precision_recall_curve(y_test_imp_np, y_pred_improved)\n",
        "pr_auc_improved = auc(recall_improved, precision_improved)\n",
        "\n",
        "print(f\"F1-мера: {f1_improved:.4f}\")\n",
        "print(f\"PR AUC: {pr_auc_improved:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5Ujw139-85O",
        "outputId": "3eb63640-da88-48ee-e328-e43ec80e724f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-мера: 0.7306\n",
            "PR AUC: 0.7913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Новые признаки и подбор гиперпараметров повысили метрики, улучшенная имплементация на таком же уровне, что улучшенный библиотечный алгоритм"
      ],
      "metadata": {
        "id": "yBwvqn0UQ2Ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сравнение"
      ],
      "metadata": {
        "id": "qHS--qp2QYws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Модель | F1-мера | PR AUC |\n",
        "|----------|-------|--------|\n",
        "| Библиотечный бейзлайн | 0.6663 | 0.7372 |\n",
        "| + Новые признаки | 0.6941 | 0.6934 |\n",
        "| + Подбор гиперпараметров | 0.7308 | 0.7992 |\n",
        "| Имплементация бейзлайн | 0.6738 | 0.7411 |\n",
        "| + Новые признаки и подбор гиперпараметров | 0.7306 | 0.7913 |"
      ],
      "metadata": {
        "id": "6LxZN1ThQcCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Регрессия"
      ],
      "metadata": {
        "id": "TOwQB9BDTdxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Бейзлайн библиотечной модели решающего дерева"
      ],
      "metadata": {
        "id": "cGfUR8zKTiRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('possum.csv')\n",
        "\n",
        "target_column = 'totlngth'\n",
        "original_feature_columns = ['age', 'hdlngth', 'skullw', 'taill', 'footlgth', 'earconch', 'eye', 'chest', 'belly']\n",
        "\n",
        "X_original = df[original_feature_columns]\n",
        "y = df[target_column]\n",
        "\n",
        "X_clean = X_original.fillna(X_original.median())\n",
        "y_clean = y.fillna(y.median())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)\n",
        "\n",
        "dt_baseline = DecisionTreeRegressor(random_state=42)\n",
        "dt_baseline.fit(X_train, y_train)\n",
        "y_pred_baseline = dt_baseline.predict(X_test)\n",
        "\n",
        "r2_baseline = r2_score(y_test, y_pred_baseline)\n",
        "mae_baseline = mean_absolute_error(y_test, y_pred_baseline)\n",
        "rmse_baseline = np.sqrt(mean_squared_error(y_test, y_pred_baseline))\n",
        "\n",
        "print(f\"R²: {r2_baseline:.3f}\")\n",
        "print(f\"MAE: {mae_baseline:.3f} см\")\n",
        "print(f\"RMSE: {rmse_baseline:.3f} см\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvfqh_JHThM1",
        "outputId": "02076617-f4a8-4105-d11a-d927bcac2b30"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R²: -0.643\n",
            "MAE: 3.524 см\n",
            "RMSE: 4.265 см\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "По метрикам видно, что самый простой бейзлайн не справляется с задачей. Добавим категориальные признаки и фиксированные гиперпараметры."
      ],
      "metadata": {
        "id": "VXu_zdIJTHA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Улучшенный бейзлайн"
      ],
      "metadata": {
        "id": "r0JoGSfJVJ4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "X_impr = df.drop(columns=[target_column, 'case'])\n",
        "y = df[target_column]\n",
        "\n",
        "numeric_features = X_impr.select_dtypes(include=[np.number]).columns.tolist()\n",
        "X_processed = X_impr.copy()\n",
        "X_processed[numeric_features] = X_processed[numeric_features].fillna(X_processed[numeric_features].median())\n",
        "\n",
        "categorical_features = ['site', 'Pop', 'sex']\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    X_processed[col] = le.fit_transform(X_processed[col].astype(str))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
        "impr_model = DecisionTreeRegressor(max_depth=3, min_samples_split=20, min_samples_leaf=10, random_state=42)\n",
        "impr_model.fit(X_train, y_train)\n",
        "y_pred_impr_ = impr_model.predict(X_test)\n",
        "\n",
        "mae_impr = mean_absolute_error(y_test, y_pred_impr_)\n",
        "rmse_impr = np.sqrt(mean_squared_error(y_test, y_pred_impr_))\n",
        "r2_impr = r2_score(y_test, y_pred_impr_)\n",
        "\n",
        "print(f\"R²:   {r2_impr:.4f}\")\n",
        "print(f\"MAE:  {mae_impr:.4f}\")\n",
        "print(f\"RMSE: {rmse_impr:.4f}\")"
      ],
      "metadata": {
        "id": "DaQaGjXiOs68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6932f70c-2794-4a4a-d32b-565585fd9bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R²:   0.2765\n",
            "MAE:  2.2952\n",
            "RMSE: 2.8299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавим подбор гиперпараметров и масштабирование для улучшения модели"
      ],
      "metadata": {
        "id": "QiWLVpYXUPgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "impr_model = DecisionTreeRegressor(max_depth=3, min_samples_split=20, min_samples_leaf=10, random_state=42)\n",
        "impr_model.fit(X_train_scaled, y_train)\n",
        "y_pred_impr_ = impr_model.predict(X_test_scaled)\n",
        "\n",
        "mae_impr = mean_absolute_error(y_test, y_pred_impr_)\n",
        "rmse_impr = np.sqrt(mean_squared_error(y_test, y_pred_impr_))\n",
        "r2_impr = r2_score(y_test, y_pred_impr_)\n",
        "\n",
        "print(f\"R²:   {r2_impr:.4f}\")\n",
        "print(f\"MAE:  {mae_impr:.4f}\")\n",
        "print(f\"RMSE: {rmse_impr:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO3aR3PYFQrG",
        "outputId": "6e7afafb-9e6e-4a65-d396-1d60d0cca3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R²:   0.2765\n",
            "MAE:  2.2952\n",
            "RMSE: 2.8299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Масштабирование не дало никакого результата"
      ],
      "metadata": {
        "id": "Eqlf4FdUGS8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'max_depth': [1, 3, 5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10, 15, 20],\n",
        "    'min_samples_leaf': [1, 2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=DecisionTreeRegressor(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "\n",
        "r2_best = r2_score(y_test, y_pred_best)\n",
        "mae_best = mean_absolute_error(y_test, y_pred_best)\n",
        "rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
        "\n",
        "print(\"Лучшие параметры:\", grid_search.best_params_)\n",
        "print(f\"R²:   {r2_best:.4f}\")\n",
        "print(f\"MAE:  {mae_best:.4f}\")\n",
        "print(f\"RMSE: {rmse_best:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDQavHaISMlI",
        "outputId": "aa7063f4-8177-4d2c-fffd-21ac53ddfb8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 15}\n",
            "R²:   0.1326\n",
            "MAE:  2.5582\n",
            "RMSE: 3.0987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подбор параметров с помощью GridSearchCV выдал параметры,  которые показали результат хуже по сравнению с фиксированнынми"
      ],
      "metadata": {
        "id": "lqN6gYWoqSfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Имплементация"
      ],
      "metadata": {
        "id": "U21YLPIPVfCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "class SimpleDecisionTreeRegressor:\n",
        "    def __init__(self, max_depth=5, min_samples_split=2, min_samples_leaf=1):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.tree = None\n",
        "\n",
        "    def _calculate_mse(self, y):\n",
        "        if len(y) == 0:\n",
        "            return 0\n",
        "        mean_val = np.mean(y)\n",
        "        return np.mean((y - mean_val) ** 2)\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        best_mse = float('inf')\n",
        "        best_feature_idx = None\n",
        "        best_threshold = None\n",
        "\n",
        "        n_features = X.shape[1]\n",
        "        for feature_idx in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature_idx])\n",
        "            for threshold in thresholds:\n",
        "                left_mask = X[:, feature_idx] <= threshold\n",
        "                right_mask = ~left_mask\n",
        "\n",
        "                if np.sum(left_mask) < self.min_samples_leaf or np.sum(right_mask) < self.min_samples_leaf:\n",
        "                    continue\n",
        "\n",
        "                mse_left = self._calculate_mse(y[left_mask])\n",
        "                mse_right = self._calculate_mse(y[right_mask])\n",
        "\n",
        "                weighted_mse = (np.sum(left_mask) * mse_left + np.sum(right_mask) * mse_right) / len(y)\n",
        "\n",
        "                if weighted_mse < best_mse:\n",
        "                    best_mse = weighted_mse\n",
        "                    best_feature_idx = feature_idx\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature_idx, best_threshold, best_mse\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        n_samples = X.shape[0]\n",
        "        if (depth >= self.max_depth or\n",
        "            n_samples < self.min_samples_split or\n",
        "            self._calculate_mse(y) == 0):\n",
        "            leaf_value = np.mean(y)\n",
        "            return {'type': 'leaf', 'value': leaf_value}\n",
        "\n",
        "        best_feature_idx, best_threshold, best_mse = self._find_best_split(X, y)\n",
        "\n",
        "        if best_feature_idx is None:\n",
        "            leaf_value = np.mean(y)\n",
        "            return {'type': 'leaf', 'value': leaf_value}\n",
        "\n",
        "        left_mask = X[:, best_feature_idx] <= best_threshold\n",
        "        right_mask = ~left_mask\n",
        "\n",
        "        left_subtree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
        "        right_subtree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
        "\n",
        "        return {\n",
        "            'type': 'split',\n",
        "            'feature_idx': best_feature_idx,\n",
        "            'threshold': best_threshold,\n",
        "            'left': left_subtree,\n",
        "            'right': right_subtree\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = X.values\n",
        "        if not isinstance(y, np.ndarray):\n",
        "            y = y.values\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _predict_sample(self, x, node):\n",
        "        if node['type'] == 'leaf':\n",
        "            return node['value']\n",
        "\n",
        "        if x[node['feature_idx']] <= node['threshold']:\n",
        "            return self._predict_sample(x, node['left'])\n",
        "        else:\n",
        "            return self._predict_sample(x, node['right'])\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = X.values\n",
        "        predictions = [self._predict_sample(x, self.tree) for x in X]\n",
        "        return np.array(predictions)\n",
        "\n",
        "df = pd.read_csv('possum.csv')\n",
        "\n",
        "target_column = 'totlngth'\n",
        "original_feature_columns = ['age', 'hdlngth', 'skullw', 'taill', 'footlgth', 'earconch', 'eye', 'chest', 'belly']\n",
        "\n",
        "X_original = df[original_feature_columns]\n",
        "y = df[target_column]\n",
        "\n",
        "X_clean = X_original.fillna(X_original.median())\n",
        "y_clean = y.fillna(y.median())\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)\n",
        "\n",
        "custom_tree = SimpleDecisionTreeRegressor(max_depth=5, min_samples_split=5, min_samples_leaf=2)\n",
        "custom_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred = custom_tree.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG4KEGgfVpxi",
        "outputId": "ffefb396-7420-4ddf-fa94-e669b6544fbb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R²: -0.1763\n",
            "MAE: 3.0010\n",
            "RMSE: 3.6085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как уже выяснилось при исследовании библиотечной модели, значимыми являются гиперпараметры"
      ],
      "metadata": {
        "id": "aIBxMTdaGfzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDecisionTreeRegressor:\n",
        "    def __init__(self, max_depth=5, min_samples_split=5, min_samples_leaf=2):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.tree = None\n",
        "\n",
        "    def _calculate_mse(self, y):\n",
        "        if len(y) == 0:\n",
        "            return 0\n",
        "        mean_val = np.mean(y)\n",
        "        return np.mean((y - mean_val) ** 2)\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        best_mse = float('inf')\n",
        "        best_feature_idx = None\n",
        "        best_threshold = None\n",
        "\n",
        "        n_features = X.shape[1]\n",
        "        for feature_idx in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature_idx])\n",
        "            for threshold in thresholds:\n",
        "                left_mask = X[:, feature_idx] <= threshold\n",
        "                right_mask = ~left_mask\n",
        "\n",
        "                if np.sum(left_mask) < self.min_samples_leaf or np.sum(right_mask) < self.min_samples_leaf:\n",
        "                    continue\n",
        "\n",
        "                mse_left = self._calculate_mse(y[left_mask])\n",
        "                mse_right = self._calculate_mse(y[right_mask])\n",
        "\n",
        "                weighted_mse = (np.sum(left_mask) * mse_left + np.sum(right_mask) * mse_right) / len(y)\n",
        "\n",
        "                if weighted_mse < best_mse:\n",
        "                    best_mse = weighted_mse\n",
        "                    best_feature_idx = feature_idx\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature_idx, best_threshold, best_mse\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        n_samples = X.shape[0]\n",
        "        if (depth >= self.max_depth or\n",
        "            n_samples < self.min_samples_split or\n",
        "            self._calculate_mse(y) == 0):\n",
        "            leaf_value = np.mean(y)\n",
        "            return {'type': 'leaf', 'value': leaf_value}\n",
        "\n",
        "        best_feature_idx, best_threshold, best_mse = self._find_best_split(X, y)\n",
        "\n",
        "        if best_feature_idx is None:\n",
        "            leaf_value = np.mean(y)\n",
        "            return {'type': 'leaf', 'value': leaf_value}\n",
        "\n",
        "        left_mask = X[:, best_feature_idx] <= best_threshold\n",
        "        right_mask = ~left_mask\n",
        "\n",
        "        left_subtree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
        "        right_subtree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
        "\n",
        "        return {\n",
        "            'type': 'split',\n",
        "            'feature_idx': best_feature_idx,\n",
        "            'threshold': best_threshold,\n",
        "            'left': left_subtree,\n",
        "            'right': right_subtree\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = X.values\n",
        "        if not isinstance(y, np.ndarray):\n",
        "            y = y.values\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _predict_sample(self, x, node):\n",
        "        if node['type'] == 'leaf':\n",
        "            return node['value']\n",
        "\n",
        "        if x[node['feature_idx']] <= node['threshold']:\n",
        "            return self._predict_sample(x, node['left'])\n",
        "        else:\n",
        "            return self._predict_sample(x, node['right'])\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not isinstance(X, np.ndarray):\n",
        "            X = X.values\n",
        "        predictions = [self._predict_sample(x, self.tree) for x in X]\n",
        "        return np.array(predictions)\n",
        "\n",
        "df = pd.read_csv('possum.csv')\n",
        "\n",
        "target_column = 'totlngth'\n",
        "original_feature_columns = ['age', 'hdlngth', 'skullw', 'taill', 'footlgth', 'earconch', 'eye', 'chest', 'belly']\n",
        "\n",
        "X_original = df[original_feature_columns]\n",
        "y = df[target_column]\n",
        "\n",
        "X_clean = X_original.fillna(X_original.median())\n",
        "y_clean = y.fillna(y.median())\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)\n",
        "\n",
        "custom_tree = SimpleDecisionTreeRegressor(max_depth=4, min_samples_split=10, min_samples_leaf=5)\n",
        "custom_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred = custom_tree.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjzSpfnAgokA",
        "outputId": "90b946d3-8930-4cb0-cc27-9c03e0b4ee61"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R²: 0.2431\n",
            "MAE: 2.2594\n",
            "RMSE: 2.8945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сравнение"
      ],
      "metadata": {
        "id": "HsWpenG-Jtvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Модель | R² | MAE | RMSE |\n",
        "|----------|-------|--------|--------|\n",
        "| Бейзлайн | -0.643 | 3.524 | 4.265 |\n",
        "| + Фиксированные параметры | 0.2765 | 2.2952 | 2.8299 |\n",
        "| + Масштабирование | 0.2765 | 2.2952 | 2.8299 |\n",
        "| + Подбор гиперпараметров | 0.1326 | 2.5582 | 3.0987 |\n",
        "| Имплементация | -0.1763 | 3.0010 | 3.6085 |\n",
        "| Имплементация с подходящими параметрами | 0.2431 | 2.2594 | 2.8945 |"
      ],
      "metadata": {
        "id": "CGqEnxpUH_xe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лучше всего себя показал бейзлайн с фиксированными параметрами. Подбор гиперпараметров с помощью GridSearchCV оказался неоптимален, что контринтуитивно. Возможно, дело в маленькой выборке данных."
      ],
      "metadata": {
        "id": "_FoqtLXxJ31T"
      }
    }
  ]
}